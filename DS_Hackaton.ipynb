{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DS"
      ],
      "metadata": {
        "id": "1JphtsHBDKYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clusterização"
      ],
      "metadata": {
        "id": "GA2b-7PdDv3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab/Practicum/HACKATON/data.csv\")"
      ],
      "metadata": {
        "id": "S1yH8sQIVsmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "CiDJfYK0Dx-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0ISv04oRwYh",
        "outputId": "6d63f1fc-d2b3-4af9-f0d7-5af89a437303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.metrics import f1_score, make_scorer, precision_score, recall_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from scipy.sparse import csr_matrix\n",
        "from catboost import CatBoostClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def run_ml_models(data, features, target):\n",
        "    results = []\n",
        "\n",
        "    # Convert categorical features into numeric features\n",
        "    le = LabelEncoder()\n",
        "    for feature in features:\n",
        "        if data[feature].dtype == \"object\":\n",
        "            data[feature] = le.fit_transform(data[feature])\n",
        "\n",
        "    # Split the data into features and target variables\n",
        "    X = data.drop(target, axis=1)\n",
        "    y = data[target]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Models and names\n",
        "    models = [\n",
        "        ('DecisionTree', DecisionTreeClassifier(random_state=42)),\n",
        "        ('RandomForest', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)),\n",
        "        ('SVM', Pipeline(steps=[('preprocessor', ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), features)])), ('classifier', SVC(kernel='linear', random_state=42))])),\n",
        "        ('NaiveBayes', MultinomialNB()),\n",
        "        ('KNN', KNeighborsClassifier(n_neighbors=5)),\n",
        "        ('CatBoost', CatBoostClassifier(logging_level='Silent')),\n",
        "        ('CatBoost_oversampled', CatBoostClassifier(logging_level='Silent'))\n",
        "    ]\n",
        "\n",
        "    for name, model in models:\n",
        "        start_time = time.time()\n",
        "        # Oversample only for CatBoost model\n",
        "        if name == 'CatBoost_oversampled':\n",
        "            # Split the data into categorical and numerical features\n",
        "            X_cat = X[features].copy()\n",
        "            X_num = X.drop(features, axis=1).copy()\n",
        "\n",
        "            # Perform oversampling using SMOTE\n",
        "            smote = SMOTE()\n",
        "            X_train_cat, y_train_cat = smote.fit_resample(X_cat, y)\n",
        "\n",
        "            # Concatenate categorical and numerical features\n",
        "            X_train = pd.concat([X_train_cat.reset_index(drop=True), X_num.reset_index(drop=True)], axis=1)\n",
        "            y_train = y_train_cat\n",
        "        else:\n",
        "            X_train = X_train\n",
        "            y_train = y_train\n",
        "\n",
        "        if name == 'NaiveBayes':\n",
        "            preprocessor = ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), features)])\n",
        "            X_train_transformed = csr_matrix(preprocessor.fit_transform(X_train))\n",
        "            X_test_transformed = csr_matrix(preprocessor.transform(X_test))\n",
        "            model.fit(X_train_transformed, y_train)\n",
        "            y_pred = model.predict(X_test_transformed)\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "        \n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        results.append([name, processing_time, precision, recall, f1])\n",
        "\n",
        "    results_df = pd.DataFrame(results, columns=['Model', 'Processing Time', 'Precision', 'Recall', 'F1'])\n",
        "    return results_df\n",
        "\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab/Practicum/HACKATON/data.csv\")\n",
        "data = data[[\"idade\", \"genero\", \"estado_civil\", \"faixa_renda\", \"bloco\"]]\n",
        "\n",
        "# Define the features and target\n",
        "features = ['idade', 'genero', 'estado_civil', 'faixa_renda']\n",
        "target = 'bloco'\n",
        "\n",
        "# Run the ML models\n",
        "results_df = run_ml_models(data, features, target)\n",
        "print(results_df.sort_values(by='F1', ascending=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV00SDwxRg8e",
        "outputId": "19b812f2-22cd-46ec-9eb4-00c7b76c6708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Model  Processing Time  Precision    Recall        F1\n",
            "6  CatBoost_oversampled         7.941518   0.476005  0.347003  0.359413\n",
            "5              CatBoost         7.902413   0.214038  0.277603  0.232204\n",
            "0          DecisionTree         0.024220   0.212949  0.264984  0.225012\n",
            "1          RandomForest         0.814208   0.187528  0.337539  0.223068\n",
            "3            NaiveBayes         0.038788   0.191453  0.334385  0.221746\n",
            "2                   SVM         0.260246   0.174412  0.321767  0.211367\n",
            "4                   KNN         0.041692   0.193612  0.280757  0.211146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justificativa para uso do parâmetro 'wighted':\n",
        "\n",
        "- O parâmetro \"weighted\" na métrica F1-score calcula a média ponderada da precisão e do recall. Ele é adequado para casos de classificação multiclasse desbalanceados, onde cada classe pode ter um número diferente de amostras. Nesse caso, o F1-score ponderado dá maior peso às classes com menos amostras, enquanto ainda considera a precisão e o recall de todas as classes. Isso permite avaliar o desempenho geral do modelo de maneira mais equilibrada, levando em conta o desequilíbrio entre as classes."
      ],
      "metadata": {
        "id": "woVC9UAIRizu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Escolha do modelo:\n",
        "\n",
        "- Com base nos resultados obtidos, é possível observar que o modelo que obteve o melhor desempenho foi o CatBoost_oversampled, que utilizou o algoritmo CatBoost e também fez uso de oversampling. Esse modelo apresentou uma precisão de 0.483, um recall de 0.365 e um F1-Score de 0.366. Isso significa que, levando em consideração todas as métricas, o modelo CatBoost_oversampled foi capaz de apresentar os melhores resultados na classificação dos dados, o que pode ser justificado pelo fato de ter sido utilizado o algoritmo CatBoost, que é conhecido por sua eficiência na modelagem de dados e classificação, além do uso de oversampling para lidar com o desbalanceamento das classes. Dessa forma, o uso do modelo CatBoost_oversampled pode ser considerado uma boa escolha para a tarefa de classificação dos dados."
      ],
      "metadata": {
        "id": "Pc8EhXAdRkCy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ykD2z338Thci"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}